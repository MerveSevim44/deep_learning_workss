{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1jHPq4m-gF7UjvioxKOvPyTjXq-57t7yz","timestamp":1716885608229},{"file_id":"1N-hQmIdl17zOd3DjadSV8MvlEoy2M8oc","timestamp":1716885103385},{"file_id":"1EI-SSwST4RWP6efVFfUrJ4qhsO931kLU","timestamp":1716879807239},{"file_id":"1koEi5DwAGQo3VxQOt-h7QHRCuOWHGTQ6","timestamp":1715094028124}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Assignment Hyperparameter Optimization"],"metadata":{"id":"UhSzBqvXk_NO"}},{"cell_type":"code","source":["# !pip uninstall tf-keras\n","# !pip install keras-tuner\n","# !pip install tensorflow==2.16.1"],"metadata":{"id":"CohUdXdZ_3us"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","import tensorflow as tf\n","print(\"Keras Current Version:\", keras.__version__, \"Tensorflow Current Version:\", tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Xg0IL3q7fOk","outputId":"9bbb8925-ad5d-45a7-c892-7bae3a478f96","executionInfo":{"status":"ok","timestamp":1716881068430,"user_tz":-120,"elapsed":316,"user":{"displayName":"Vahit Keskin","userId":"01629533593928328348"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Keras Current Version: 3.3.3 Tensorflow Current Version: 2.16.1\n"]}]},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"4fkaU13ZlJps"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from joblib import dump, load\n","import random\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.initializers import RandomNormal, RandomUniform, GlorotUniform, GlorotNormal, HeNormal\n","from keras.optimizers.schedules import ExponentialDecay\n","from keras_tuner import RandomSearch, GridSearch, BayesianOptimization\n","from keras_tuner.engine.hyperparameters import HyperParameters\n","\n","random.seed(46)\n","np.random.seed(46)\n","tf.random.set_seed(46)\n","\n","# import os\n","import time\n"],"metadata":{"id":"a5JXY1-PidHB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"AGxuS3MVhyHV"}},{"cell_type":"code","source":["def preprocess_data(filepath):\n","    data = pd.read_csv(filepath)\n","    scaler = StandardScaler()\n","    X = scaler.fit_transform(data.drop('Outcome', axis=1))\n","    y = data['Outcome'].values\n","    dump(scaler, 'scaler.joblib')\n","    return X, y\n","\n","def prepare_datasets(X_train, X_val, y_train, y_val, batch_size=None):\n","    if batch_size is None:\n","        batch_size = len(X_train)\n","    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","    train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(batch_size)\n","    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n","    val_dataset = val_dataset.batch(batch_size)\n","    return train_dataset, val_dataset\n","\n","def plot_training_history(history, train_loss='loss', train_metric='accuracy', val_loss='val_loss', val_metric='val_accuracy'):\n","\n","    #Loss\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(history.history[train_loss], label='Training Loss')\n","    plt.plot(history.history[val_loss], label='Validation Loss')\n","    plt.title('Training and Validation Loss Over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Metrics\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(history.history[train_metric], label=f\"Training: {train_metric}\")\n","    plt.plot(history.history[val_metric], label=f\"Validation: {val_metric}\")\n","    plt.title(f'Training and Validation {train_metric} Over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel(f'train_metric')\n","    plt.legend()\n","    plt.show()\n","\n","def get_best_epoch_details(history):\n","    val_losses = history.history['val_loss']\n","    min_val_loss_index = val_losses.index(min(val_losses))\n","    best_epoch = min_val_loss_index + 1\n","\n","    epoch_details = {}\n","    for key in history.history.keys():\n","        epoch_details[key] = history.history[key][min_val_loss_index]\n","\n","    epoch_details['best_epoch'] = best_epoch\n","    print(f\"Best epoch details: {epoch_details}\")"],"metadata":{"id":"qmBVpPJ0hz33"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preparation"],"metadata":{"id":"GQcoZeUPhjEV"}},{"cell_type":"code","source":["X, y = preprocess_data('/content/diabetes.csv')\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","train_ds, val_ds = prepare_datasets(X_train, X_val, y_train, y_val, batch_size=32)"],"metadata":{"id":"o9V6zzvdgwUB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 1: Hiperparametre arama uzayını aşağıdaki değerlere göre oluşturunuz:"],"metadata":{"id":"vIc22cikxC6B"}},{"cell_type":"markdown","source":["**Layer sayısı**:  1-10\n","\n","**Unit sayısı**: 32-512 arasında 16'şar artacak şekilde.\n","\n","**Aktivasyon fonksiyonları**: relu, tanh, sigmoid\n","\n","**l2**: 0.0001-0.01\n","\n","**dropout**: 0.1-0.5 arasında 0.05 artacak şekilde.\n","\n","**initial learning rate**: 0.0001-0.01 (1e-4 - 1e-2)\n","\n","**learning rate scheduler**: decay steps: 20\n","\n","**optimizer'lar**: 'sgd', 'adam', 'rmsprop' (olduğu gibi kalabilir)\n","\n","**Random search:** epoch sayısı en az 200 olmalı\n","\n","Diğer ayarları dilediğiniz gibi yapabilirsiniz."],"metadata":{"id":"51c98zGKCqpX"}},{"cell_type":"code","source":["def build_model(hp):\n","    model = Sequential()\n","    model.add(Input(shape=(train_ds.element_spec[0].shape[1],)))\n","\n","    # Hidden layers, activation functions, l2, Dropout\n","    for i in range(hp.Int(####)):\n","\n","        model.add(Dense(units=hp.Int(####),\n","                        activation=hp.Choice('activation_' + str(i), ####),\n","                        kernel_regularizer=l2(hp.Float(####))))\n","\n","        model.add(BatchNormalization())\n","        model.add(Dropout(hp.Float(####)))\n","\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    # Learning rate schedule\n","    initial_learning_rate = hp.Float(####)\n","\n","    lr_schedule = ExponentialDecay(\n","        initial_learning_rate=initial_learning_rate,\n","        decay_steps=#,\n","        decay_rate=0.96,\n","        staircase=True\n","    )\n","\n","    # optimizers\n","    optimizer_choice = hp.Choice('optimizer', values=['sgd', 'adam', \"rmsprop\"])\n","    if optimizer_choice == 'sgd':\n","        optimizer = SGD(\n","            learning_rate=lr_schedule,\n","            momentum=hp.Float('momentum', min_value=0.0, max_value=0.9, step=0.1)\n","        )\n","    elif optimizer_choice == 'adam':\n","        optimizer = Adam(\n","            learning_rate=lr_schedule,\n","            beta_1=hp.Float('beta1', min_value=0.85, max_value=0.99, step=0.01),\n","            beta_2=hp.Float('beta2', min_value=0.999, max_value=0.9999, step=0.0001),\n","            epsilon=hp.Float('epsilon', min_value=1e-8, max_value=1e-7, step=1e-8)\n","        )\n","\n","    elif optimizer_choice == 'rmsprop':\n","        optimizer = RMSprop(\n","            learning_rate=lr_schedule,\n","            rho=hp.Float('rho', min_value=0.8, max_value=0.99, step=0.01),\n","            epsilon=hp.Float('epsilon', min_value=1e-10, max_value=1e-8, step=1e-10),\n","            momentum=hp.Float('momentum', min_value=0.0, max_value=0.9, step=0.1)\n","        )\n","\n","    model.compile(optimizer=optimizer,\n","                  loss=\"binary_crossentropy\",\n","                  metrics=[\"accuracy\"])\n","\n","    return model"],"metadata":{"id":"P9qovA7mtTNj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 2: Epoch sayısı 200 olacak şekilde aramayı başlatınız. Diğer ayarlar aynı kalabilir.\n","\n"],"metadata":{"id":"nBs92yv0myjk"}},{"cell_type":"code","source":[],"metadata":{"id":"XYEI8pJbs2GA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"p-jK6fG5s2KE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 3: En iyi 3 hiperparametre setini getiriniz, ayrı ayrı kaydediniz, değerlerini inceleyiniz, bazı hiperparametre değerlerini yorumlayınız."],"metadata":{"id":"fQEYTn2SpgMr"}},{"cell_type":"code","source":[],"metadata":{"id":"lgSUmFVys2Mr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cUFtj26fIB7y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ctXttysPH2wv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6pPAh77fH2yw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"38C0dcX4H208"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9ga4URTiPaMQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 4: En iyi 3 modeli seçiniz."],"metadata":{"id":"6oFm0osqNQ0-"}},{"cell_type":"code","source":[],"metadata":{"collapsed":true,"id":"b3947zzTNT3X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 5: En iyi 3 modelin bir döngü aracılığı ile model başarısını hesaplayınız"],"metadata":{"id":"eLJ9nsYBNWhS"}},{"cell_type":"code","source":[],"metadata":{"id":"8MglzKCDH23K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 6: Modellerin accuracy değerleri arasında neden fark var? En tepedeki modelin en iyi olmasını bekleriz, eğer öyle değilse neden en tepedekinin accuracy değeri en yüksek değil?"],"metadata":{"id":"h-XVRytTOYuU"}},{"cell_type":"code","source":[],"metadata":{"id":"0CtBdY-YOpEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lSmONtq_aLgr"},"execution_count":null,"outputs":[]}]}